{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Naive Bayes\n",
        "\n",
        "Provide an brief overview of Naive Bayes classification and how it works.\n",
        "Don’t go into too much detail, assume the audience is familiar with math and statistics but is not familiar with Naive Bayes.\n",
        "Explain the probabilistic nature of Naive Bayes and its Bayes’ theorem foundation.\n",
        "Clearly define the objectives of what you are trying to do.\n",
        "Explain what you aim to achieve through Naive Bayes classification.\n",
        "Describe different variants of Naive Bayes, such as Gaussian, Multinomial, and Bernoulli Naive Bayes, and explain when to use each\n",
        "\n",
        "Bayes Theorem is a mathematical theorem used for predicting a future outcome depending on a collected piece of evidence. More specifically, this theorem calculates \"conditional probabilities\", which depicts the probability of an outcome based on a prior condition/ event. The formula for the theorem is: \n",
        "$\\[P(A|B) = (P(B|A) (P(A))) / P(B) \\]\n",
        "In this formula, to predict the probability of event A given event B, we multiply the probability of event B when event A occurs by the probability of event A. We then divide the product by the total probability of event B.\n",
        "With that in mind, Naive Bayes is a...\n",
        "There are many variants under the umbrella of Naive Bayes. Included in this bunch are Complement Naive Bayes, Out- of- core Naive Bayes model- fitting, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes. When speaking of Gaussian Naive Bayes... Whereas, Bernoulli Naive Bayes... Likewise, Multinomial Naive Bayes... \n",
        "(Week 7 lecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Prep\n",
        "\n",
        "To prepare for Naive Bayes classification, I split my dataset into training and testing datasets. I do this by .. Once partitioned, there should be a training set-- which consists of the training set as well as a validation set, to do a minor evaluation on what has been trained-- and a test set. The purpose of the partitions of different sets is so I can inform my model of what categories to look for when actually classifying my collected datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "#import pycountry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "appledf = pd.read_csv(\"../websitedata/apple_py.csv\")\n",
        "\n",
        "newAppledf = pd.read_csv(\"../websitedata/newApple_py.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = appledf[\"Peak\"]\n",
        "y=np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[484, 582, 534, 49, 699, 192, 521, 525, 701, 763]\n",
            "[680, 295, 425, 506, 136, 602, 270, 683, 533, 766]\n"
          ]
        }
      ],
      "source": [
        "#training, validation, and testing sets\n",
        "import random\n",
        "\n",
        "x = newAppledf.to_numpy()\n",
        "N = x.shape[0]\n",
        "l = [*range(N)]     # indices\n",
        "cut = int(0.8 * N) #80% of the list\n",
        "random.shuffle(l)   # randomize\n",
        "train_index = l[:cut] # first 80% of shuffled list\n",
        "test_index = l[cut:] # last 20% of shuffled list\n",
        "\n",
        "#little validation set from training set\n",
        "#valid = int(0.1 * len(train_index))  # 10% of training set will be used as a validation set\n",
        "#random.shuffle(train_index)\n",
        "#val_index = train_index[:valid]\n",
        "#train_index = train_index[valid:]\n",
        "\n",
        "#x_valid = x[val_index]\n",
        "#y_valid = y[val_index]\n",
        "\n",
        "print(train_index[0:10])\n",
        "print(test_index[0:10])\n",
        "\n",
        "set_train = set(train_index)\n",
        "set_test = set(test_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection\n",
        "\n",
        "You need to use either R or Python to code Naive Bayes (NB) as a classification model for your data, we will use NB as a wrapper for feature selection. While not required, if you want to take it further, you can try this in both R and Python.\n",
        "\n",
        "Objective: The primary objective of the Feature Selection component in this project is to identify and choose the most relevant and informative features (variables or attributes) from the dataset, for the given task. Effective feature selection can improve the model’s performance, reduce overfitting, and enhance the interpretability of the results.\n",
        "\n",
        "Instructions: Generalize and apply the code in the lab assignment and lab-demonstration called “Feature selection with text data” to the text and record data you have collected for your project. This code demonstrates feature selection for a text classification task, so map the task onto your projects dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5245687484260891\n",
            "25775958.26785101\n"
          ]
        }
      ],
      "source": [
        "# COMPUTE UPPER AND LOWER LIMIT FOR VARIANCE ACCROSS SAMPLES\n",
        "x_var=np.var(x,axis=0)\n",
        "print(np.min(x_var))\n",
        "print(np.max(x_var))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results- Record Data\n",
        "\n",
        "Using your optimal feature set from the previous section, fit a final “optimal” NB model for your Record data.\n",
        "Report and comment on the findings. It is required that you create code, appropriate visualizations, result summaries, confusion matrices, etc\n",
        "Describe how the trained model is tested on the testing dataset.\n",
        "Discuss the evaluation metrics used to assess the performance of the Naive Bayes classifier (e.g., accuracy, precision, recall, F1-score).\n",
        "Discuss the concepts of overfitting and under-fitting and whether your model is doing it.\n",
        "Discuss the model’s performance in terms of accuracy and other relevant metrics.\n",
        "Describe how the project findings will be documented and reported, including the format of reports or presentations.\n",
        "e.g. what is the output that you generate. What does the output mean? What does it tell you about your data? Does your model do a good job of predicting your test data? Include and discuss relevant visualizations, results, the confusion matrices, etc .\n",
        "Create and include a minimum of three visualizations for each case (text and record classification).\n",
        "Write a conclusion paragraph interpreting the results. Note, this is not the same as a write-up of technical methodological details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results- Text Data\n",
        "\n",
        "Repeat HW-3.2.3 but with your text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def train_MNB_model(X,Y, i_print=False):\n",
        "\n",
        "    if(i_print):\n",
        "        print(X.shape,Y.shape)\n",
        "\n",
        "    #SPLIT\n",
        "    x_train=X[train_index]\n",
        "    y_train=Y[train_index].flatten()\n",
        "\n",
        "    x_test=X[test_index]\n",
        "    y_test=Y[test_index].flatten()\n",
        "\n",
        "\n",
        "    # INITIALIZE MODEL\n",
        "    model = MultinomialNB()\n",
        "    \n",
        "    # TRAIN MODEL \n",
        "    start = time.process_time()\n",
        "    model.fit(x_train,y_train)\n",
        "    time_train=time.process_time() - start\n",
        "\n",
        "    # LABEL PREDICTIONS FOR TRAINING AND TEST SET \n",
        "    start = time.process_time()\n",
        "    yp_train = model.predict(x_train)\n",
        "    yp_test = model.predict(x_test)\n",
        "    time_eval=time.process_time() - start\n",
        "\n",
        "    acc_train= accuracy_score(y_train, yp_train)*100\n",
        "    acc_test= accuracy_score(y_test, yp_test)*100\n",
        "\n",
        "    if(i_print):\n",
        "        print(acc_train, acc_test, time_train,time_eval)\n",
        "\n",
        "    return (acc_train, acc_test, time_train,time_eval)\n",
        "\n",
        "\n",
        "#TEST\n",
        "print(type(x),type(y))\n",
        "print(x.shape,y.shape)\n",
        "(acc_train, acc_test,time_train,time_eval)=train_MNB_model(x,y,i_print=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def report(y,ypred):\n",
        "      #ACCURACY COMPUTE \n",
        "      print(\"Accuracy:\",accuracy_score(y, ypred)*100)\n",
        "      print(\"Number of mislabeled points out of a total %d points = %d\"\n",
        "            % (y.shape[0], (y != ypred).sum()))\n",
        "\n",
        "def print_model_summary():\n",
        "      # LABEL PREDICTIONS FOR TRAINING AND TEST SET \n",
        "      yp_train = model.predict(x_train)\n",
        "      yp_test = model.predict(x_test)\n",
        "\n",
        "      print(\"ACCURACY CALCULATION\\n\")\n",
        "\n",
        "      print(\"TRAINING SET:\")\n",
        "      report(y_train,yp_train)\n",
        "\n",
        "      print(\"\\nTEST SET (UNTRAINED DATA):\")\n",
        "      report(y_test,yp_test)\n",
        "\n",
        "      print(\"\\nCHECK FIRST 20 PREDICTIONS\")\n",
        "      print(\"TRAINING SET:\")\n",
        "      print(y_train[0:20])\n",
        "      print(yp_train[0:20])\n",
        "      print(\"ERRORS:\",yp_train[0:20]-y_train[0:20])\n",
        "\n",
        "      print(\"\\nTEST SET (UNTRAINED DATA):\")\n",
        "      print(y_test[0:20])\n",
        "      print(yp_test[0:20])\n",
        "      print(\"ERRORS:\",yp_test[0:20]-y_test[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "#OUTPUT FOLDER: START FRESH (DELETE OLD ONE IF EXISTS)\n",
        "output_dir = \"output\"\n",
        "if os.path.exists(output_dir) and os.path.isdir(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.mkdir(output_dir)\n",
        "\n",
        "newAppledf=pd.read_csv(\"apple.csv\")\n",
        "print(newAppledf.shape)\n",
        "print(newAppledf.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##UTILITY FUNCTION TO INITIALIZE RELEVANT ARRAYS\n",
        "def initialize_arrays():\n",
        "    global num_features,train_accuracies\n",
        "    global test_accuracies,train_time,eval_time\n",
        "    num_features=[]\n",
        "    train_accuracies=[]\n",
        "    test_accuracies=[]\n",
        "    train_time=[]\n",
        "    eval_time=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# INITIALIZE ARRAYS\n",
        "initialize_arrays()\n",
        "\n",
        "# DEFINE SEARCH FUNCTION\n",
        "def partial_grid_search(num_runs, min_index, max_index):\n",
        "    for i in range(1, num_runs+1):\n",
        "        # SUBSET FEATURES \n",
        "        upper_index=min_index+i*int((max_index-min_index)/num_runs)\n",
        "        xtmp=x[:,0:upper_index]\n",
        "\n",
        "        #TRAIN \n",
        "        (acc_train,acc_test,time_train,time_eval)=train_MNB_model(xtmp,y,i_print=False)\n",
        "\n",
        "        if(i%5==0):\n",
        "            print(i,upper_index,xtmp.shape[1],acc_train,acc_test)\n",
        "            \n",
        "        #RECORD \n",
        "        num_features.append(xtmp.shape[1])\n",
        "        train_accuracies.append(acc_train)\n",
        "        test_accuracies.append(acc_test)\n",
        "        train_time.append(time_train)\n",
        "        eval_time.append(time_eval)\n",
        "\n",
        "# DENSE SEARCH (SMALL NUMBER OF FEATURES (FAST))\n",
        "partial_grid_search(num_runs=100, min_index=0, max_index=1000)\n",
        "\n",
        "# SPARSE SEARCH (LARGE NUMBER OF FEATURES (SLOWER))\n",
        "partial_grid_search(num_runs=20, min_index=1000, max_index=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#UTILITY FUNCTION TO SAVE RESULTS\n",
        "def save_results(path_root):\n",
        "    out=np.transpose(np.array([num_features,train_accuracies,test_accuracies,train_time,eval_time])) \n",
        "    out=pd.DataFrame(out)\n",
        "    out.to_csv(path_root+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#UTILITY FUNCTION TO PLOT RESULTS\n",
        "def plot_results(path_root):\n",
        "\n",
        "    #PLOT-1\n",
        "    plt.plot(num_features,train_accuracies,'-or')\n",
        "    plt.plot(num_features,test_accuracies,'-ob')\n",
        "    plt.xlabel('Number of features')\n",
        "    plt.ylabel('ACCURACY: Training (blue) and Test (red)')\n",
        "    plt.savefig(path_root+'-1.png')\n",
        "    plt.show()\n",
        "\n",
        "    # #PLOT-2\n",
        "    plt.plot(num_features,train_time,'-or')\n",
        "    plt.plot(num_features,eval_time,'-ob')\n",
        "    plt.xlabel('Number of features')\n",
        "    plt.ylabel('Runtime: training time (red) and evaluation time(blue)')\n",
        "    plt.savefig(path_root+'-2.png')\n",
        "    plt.show()\n",
        "\n",
        "    # #PLOT-3\n",
        "    plt.plot(np.array(test_accuracies),train_time,'-or')\n",
        "    plt.plot(np.array(test_accuracies),eval_time,'-ob')\n",
        "    plt.xlabel('test_accuracies')\n",
        "    plt.ylabel('Runtime: training time (red) and evaluation time (blue)')\n",
        "    plt.savefig(path_root+'-3.png')\n",
        "    plt.show()\n",
        "\n",
        "    # #PLOT-3\n",
        "    plt.plot(num_features,np.array(train_accuracies)-np.array(test_accuracies),'-or')\n",
        "    plt.xlabel('Number of features')\n",
        "    plt.ylabel('train_accuracies-test_accuracies')\n",
        "    plt.savefig(path_root+'-4.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "save_results(output_dir+\"/partial_grid_search\")\n",
        "plot_results(output_dir+\"/partial_grid_search\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
