[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "!(./images/my_imageme.png)\nOfure Udabor is a current first- year student in the Data Science and Analytics program at Georgetown University. She received her B.A. in Psychology and Economics from the University of Texas at Austin in 2022, where she her research focused on sociological effects of psychological and economic phenomena. During her undergraduate studies, she interned as a Data Analyst for an ecommerce brand and worked as a manager for a healthcare company while receiving academic accolades– such as University Honors– and merit scholarships– such as the Walter B. Smith Jr. Undergraduate Scholarship. Now as a graduate student, she hopes to gain a deep understanding of data science and how it can be leveraged in marketing to gain stronger insights from consumer behavior."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nGeorgetown University | Washington, DC\nM.S. in Data Science and Analytics | Aug 2023 - Present\nUniveristy of Texas at Austin | Austin, Texas\nB.A in Economics; B.A. in Psychology | Aug 2018 - May 2022"
  },
  {
    "objectID": "about.html#academic-interests",
    "href": "about.html#academic-interests",
    "title": "About",
    "section": "Academic Interests",
    "text": "Academic Interests\n\nNatural Language Processing\nMarketing Analytics\nDecision Analysis"
  },
  {
    "objectID": "Classification.html",
    "href": "Classification.html",
    "title": "",
    "section": "",
    "text": "Classification"
  },
  {
    "objectID": "datagathering.html",
    "href": "datagathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "The data I gathered to examine how the sentiments of current music and media coincide with the general happiness levels of different countries consists of text data, qualitative record data, and quantitative record data. The data comes from five different main sources, two of which are directly from website API (Application Programming Interface) sources. As an overview of the data sources:\nApple Music International Rankings: Displays the Apple Music rankings for the top international songs in October 2023.\nSpotify: Contains variables that give a summary of different aspects of an artist’s various songs and albums over the years\nTop Netflix TV Shows in 2022: Consists of the top television shows worldwide on Netflix’s streaming platform.\nGDP vs. Happiness: This data explores the various levels of happiness and the Gross Domestic Product (GDP) per capita spanning different years for each country.\nWikipedia: Contains text data from specific WIkipedia topic pages.\n\nApple Music\nOne of my goals for this project was to get a large dataset representing the current top rated songs in various countries. After searching a bit, I was able to discover Kworb’s website filled with real- time data on how Apple Music’s international listeners are ranking songs. Below is a picture of the raw data, which shows the artist, their song, their song’s ranking in different countries, the duration of their ranking position, and the amounts of points accumulated that verify their ranking position.\n\n\n\nApple Music International Rankings Raw Dataset"
  },
  {
    "objectID": "datagathering.html#data-sources",
    "href": "datagathering.html#data-sources",
    "title": "Data Gathering",
    "section": "",
    "text": "My original data sources include datasets from kworb.net and dataworld.com that document rankings as of October 12, 2023."
  },
  {
    "objectID": "datagathering.html#data-sites",
    "href": "datagathering.html#data-sites",
    "title": "Data Gathering",
    "section": "Data Sites",
    "text": "Data Sites"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Mood, Music, and Media",
    "section": "",
    "text": "As the prevalence of daily technological usage grows, streaming platforms continue to permeate the infrastructure of societal pastimes. Music streaming platforms such as Apple Music and Spotify, as well as streaming services such as Hulu and Netflix, are becoming increasingly popular due to providing a plethora of entertainment at one’s fingertips. Due to this distinctive growth in an array of highly- accessible media, a desire to cater to individual consumers– and a desire by consumers to be presented with more specialized content– is also increasing. Inspired by works already implemented, my project aims to examine if the self- reported happiness level of a person in the past- year will have a significant impact on their media consumption preferences today.\n\nMedia\nMedia consumption being tied to emotional state is not a new topic. One study in 1988 used factor analysis on a group of one hundred American students attending university to gauge their reasons for attending movie theaters and the preferences for the movies they watch. The three main reasons consisted of intentional escapism, desires of self improvement, and genuine entertainment. However, even more insightful, was the researchers being able to make out that the movie theater attendees who went for escapism, “preferred movies with an air of unreality” (Abraham Tesser and Wu (1988)). This illustrates how consumers desire to see a part of themselves– or a part they hope to gain– in the various things they consume.\nTaking a more comprehensive approach to present a complementary notion, a more recent study explores how instrumental considering the emotional state of the consumer is to media recommendation. Winoto and Yang (2010) had seventy- seven college students in the midst of final exams’ season participate in their experiment, where they answered questions revolving around 46 movies and 16 sentiment labels. This study yielded insights such as possessing positive- affect and negative- affect have a significant effect on the rating of romantic- comedy movies. Another takeaway is the observation that user recommendation systems may not be as successful when the said user is, “not in the mood to enjoy a movie” (Winoto and Tang (2010)). Taking into account physical exhaustion levels and general mood, the study demonstrates just a fraction of how specific the external and internal influences can be on increasing the bias which affects media consumption preferences.\n\n\nQuestions:\n\nExamples of American pop culture colloquialisms? OR Example of adopted pop culture colloquialisms?\nWhat regions in the United States have more of an effect on shared national colloquialisms?\nWhat regions globally have more of an effect on shared national colloquialisms (limited to seven continents)?\nIs there a specific age group who is more impressionable to imported jargon?\nIs there a specific region who is more impressionable to imported jargon?\nLargest language dispersion channel (like Netflix, Hulu, Amazon Prime, Apple TV)?\nIs genre influential on how adaptable the terms are?\nDoes positive or negative content have more of an effect on adapted jargon?\nPractical applications for encouraging international colloquialisms dispersal?\nHow can these applications adapt to the growth of international colloquialisms in America?\n\n\n\n\n\n\nReferences\n\nAbraham Tesser, Karen Millar, and Cheng-Huan Wu. 1988. “On the Perceived Functions of Movies.” The Journal of Psychology 122 (5): 441–49. https://doi.org/10.1080/00223980.1988.10542949.\n\n\nWinoto, Pinata, and Tiffany Y. Tang. 2010. “The Role of User Mood in Movie Recommendations.” Expert Systems with Applications 37 (8): 6086–92. https://doi.org/https://doi.org/10.1016/j.eswa.2010.02.117."
  },
  {
    "objectID": "naivebayes.html",
    "href": "naivebayes.html",
    "title": "Naive Bayes",
    "section": "",
    "text": "Provide an brief overview of Naive Bayes classification and how it works. Don’t go into too much detail, assume the audience is familiar with math and statistics but is not familiar with Naive Bayes. Explain the probabilistic nature of Naive Bayes and its Bayes’ theorem foundation. Clearly define the objectives of what you are trying to do. Explain what you aim to achieve through Naive Bayes classification. Describe different variants of Naive Bayes, such as Gaussian, Multinomial, and Bernoulli Naive Bayes, and explain when to use each\nBayes Theorem is a mathematical theorem used for predicting a future outcome depending on a collected piece of evidence. More specifically, this theorem calculates “conditional probabilities”, which depicts the probability of an outcome based on a prior condition/ event. The formula for the theorem is: $[P(A|B) = (P(B|A) (P(A))) / P(B) ] In this formula, to predict the probability of event A given event B, we multiply the probability of event B when event A occurs by the probability of event A. We then divide the product by the total probability of event B. With that in mind, Naive Bayes is a… There are many variants under the umbrella of Naive Bayes. Included in this bunch are Complement Naive Bayes, Out- of- core Naive Bayes model- fitting, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes. When speaking of Gaussian Naive Bayes… Whereas, Bernoulli Naive Bayes… Likewise, Multinomial Naive Bayes… (Week 7 lecture)\n\n\n\nTo prepare for Naive Bayes classification, I split my dataset into training and testing datasets. I do this by .. Once partitioned, there should be a training set– which consists of the training set as well as a validation set, to do a minor evaluation on what has been trained– and a test set. The purpose of the partitions of different sets is so I can inform my model of what categories to look for when actually classifying my collected datasets.\n\n\n\nYou need to use either R or Python to code Naive Bayes (NB) as a classification model for your data, we will use NB as a wrapper for feature selection. While not required, if you want to take it further, you can try this in both R and Python.\nObjective: The primary objective of the Feature Selection component in this project is to identify and choose the most relevant and informative features (variables or attributes) from the dataset, for the given task. Effective feature selection can improve the model’s performance, reduce overfitting, and enhance the interpretability of the results.\nInstructions: Generalize and apply the code in the lab assignment and lab-demonstration called “Feature selection with text data” to the text and record data you have collected for your project. This code demonstrates feature selection for a text classification task, so map the task onto your projects dataset.\n\n\n\nUsing your optimal feature set from the previous section, fit a final “optimal” NB model for your Record data. Report and comment on the findings. It is required that you create code, appropriate visualizations, result summaries, confusion matrices, etc Describe how the trained model is tested on the testing dataset. Discuss the evaluation metrics used to assess the performance of the Naive Bayes classifier (e.g., accuracy, precision, recall, F1-score). Discuss the concepts of overfitting and under-fitting and whether your model is doing it. Discuss the model’s performance in terms of accuracy and other relevant metrics. Describe how the project findings will be documented and reported, including the format of reports or presentations. e.g. what is the output that you generate. What does the output mean? What does it tell you about your data? Does your model do a good job of predicting your test data? Include and discuss relevant visualizations, results, the confusion matrices, etc . Create and include a minimum of three visualizations for each case (text and record classification). Write a conclusion paragraph interpreting the results. Note, this is not the same as a write-up of technical methodological details."
  },
  {
    "objectID": "naivebayes.html#introduction-to-naive-bayes",
    "href": "naivebayes.html#introduction-to-naive-bayes",
    "title": "Naive Bayes",
    "section": "",
    "text": "Provide an brief overview of Naive Bayes classification and how it works. Don’t go into too much detail, assume the audience is familiar with math and statistics but is not familiar with Naive Bayes. Explain the probabilistic nature of Naive Bayes and its Bayes’ theorem foundation. Clearly define the objectives of what you are trying to do. Explain what you aim to achieve through Naive Bayes classification. Describe different variants of Naive Bayes, such as Gaussian, Multinomial, and Bernoulli Naive Bayes, and explain when to use each\nBayes Theorem is a mathematical theorem used for predicting a future outcome depending on a collected piece of evidence. More specifically, this theorem calculates “conditional probabilities”, which depicts the probability of an outcome based on a prior condition/ event. The formula for the theorem is: $[P(A|B) = (P(B|A) (P(A))) / P(B) ] In this formula, to predict the probability of event A given event B, we multiply the probability of event B when event A occurs by the probability of event A. We then divide the product by the total probability of event B. With that in mind, Naive Bayes is a… There are many variants under the umbrella of Naive Bayes. Included in this bunch are Complement Naive Bayes, Out- of- core Naive Bayes model- fitting, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes. When speaking of Gaussian Naive Bayes… Whereas, Bernoulli Naive Bayes… Likewise, Multinomial Naive Bayes… (Week 7 lecture)"
  },
  {
    "objectID": "naivebayes.html#data-prep",
    "href": "naivebayes.html#data-prep",
    "title": "Naive Bayes",
    "section": "",
    "text": "To prepare for Naive Bayes classification, I split my dataset into training and testing datasets. I do this by .. Once partitioned, there should be a training set– which consists of the training set as well as a validation set, to do a minor evaluation on what has been trained– and a test set. The purpose of the partitions of different sets is so I can inform my model of what categories to look for when actually classifying my collected datasets."
  },
  {
    "objectID": "naivebayes.html#feature-selection",
    "href": "naivebayes.html#feature-selection",
    "title": "Naive Bayes",
    "section": "",
    "text": "You need to use either R or Python to code Naive Bayes (NB) as a classification model for your data, we will use NB as a wrapper for feature selection. While not required, if you want to take it further, you can try this in both R and Python.\nObjective: The primary objective of the Feature Selection component in this project is to identify and choose the most relevant and informative features (variables or attributes) from the dataset, for the given task. Effective feature selection can improve the model’s performance, reduce overfitting, and enhance the interpretability of the results.\nInstructions: Generalize and apply the code in the lab assignment and lab-demonstration called “Feature selection with text data” to the text and record data you have collected for your project. This code demonstrates feature selection for a text classification task, so map the task onto your projects dataset."
  },
  {
    "objectID": "naivebayes.html#results--record-data",
    "href": "naivebayes.html#results--record-data",
    "title": "Naive Bayes",
    "section": "",
    "text": "Using your optimal feature set from the previous section, fit a final “optimal” NB model for your Record data. Report and comment on the findings. It is required that you create code, appropriate visualizations, result summaries, confusion matrices, etc Describe how the trained model is tested on the testing dataset. Discuss the evaluation metrics used to assess the performance of the Naive Bayes classifier (e.g., accuracy, precision, recall, F1-score). Discuss the concepts of overfitting and under-fitting and whether your model is doing it. Discuss the model’s performance in terms of accuracy and other relevant metrics. Describe how the project findings will be documented and reported, including the format of reports or presentations. e.g. what is the output that you generate. What does the output mean? What does it tell you about your data? Does your model do a good job of predicting your test data? Include and discuss relevant visualizations, results, the confusion matrices, etc . Create and include a minimum of three visualizations for each case (text and record classification). Write a conclusion paragraph interpreting the results. Note, this is not the same as a write-up of technical methodological details."
  },
  {
    "objectID": "dataexploration.html",
    "href": "dataexploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Begin by thoroughly understanding the dataset and the problem you are trying to solve. Familiarize yourself with the characteristics of each feature, including their data types (numerical, categorical), potential relationships, and relevance to the project’s objectives.\nMy collected data is meant to display major representative sources of American pop culture. This currently includes headlines from newpapers, top music songs internationally, and the most liked Netflix shows from the past year. As these sources are known to reflect what the general population is interested in, these datasets that seemingly represent America’s favored pasttimes, also present current wave of cultural influence in America. Of these influences, I aim to see how certain streaming services are most influential on the colloquialisms of America.\n\n\n\nCalculate and report basic summary statistics such as mean, median, mode, standard deviation, and variance for numerical variables. For categorical variables, provide frequency distributions and bar charts to visualize data distribution.\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(appledf.describe())\n\nnewAppledf = appledf.drop([\"Artist and Title\", \"Country\"], axis=1)\nnewAppledf = newAppledf.reset_index(drop=True)\n\nprint(newAppledf.describe())\n\n\n\n\n\nApple Analysis Summary Statistics\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(netflixdf.describe())\n\n\n\n\n\nNetflix Summary Statistics\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(df_new.describe())\nprint(df_newer.describe())\nprint(df_newest.describe())\n\n\n\n\n\n\nCreate visualizations such as histograms, box plots, scatter plots, and heatmaps to explore the data’s distribution, relationships between variables, and potential patterns or trends. Visualizations can make complex data more interpretable.\n\n\n\nExamine the correlations between variables using correlation matrices, heat-maps, or scatter plots. Identify which variables are positively, negatively, or not correlated, which can guide further analysis.\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(appledf.corr())\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(netflixdf.corr())\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(df_new.corr())\nprint(df_newer.corr())\nprint(df_newest.corr())\n\n\n\n\n\n\n\n\n\nExamples of American pop culture colloquialisms? OR Example of adopted pop culture colloquialisms?\nWhat regions in the United States have more of an effect on shared national colloquialisms?\nWhat regions globally have more of an effect on shared national colloquialisms (limited to seven continents)?\nIs there a specific genre that is more influential on imported jargon?\nIs there a specific region who is more impressionable to imported jargon?\nBased on the data collected, would media or music streaming services be more influential on imported jargon?\nIs national language relation to english influential on how adaptable the terms are?\nDoes positive or negative content have more of an effect on adapted jargon?\nPractical applications for encouraging international colloquialisms dispersal?\nHow can these applications adapt to the growth of international colloquialisms in America?\n\nHypothesis: I believe the rise of international content being consumed through streaming platforms and the rise in the incorporation of internationally- influenced colloquialisms in America will yield a positive correlation.\n\n\n\n\nIf applicable, group or segment the data based on relevant criteria to uncover insights within specific subgroups.\n\n\n\nDetect and investigate outliers that may indicate data quality issues or reveal interesting anomalies in the dataset.\n\n\n\nSummarize the key findings, insights, and patterns discovered during the EDA phase. Present these findings in a clear and organized manner, using textual narration, tables, charts, and narrative descriptions.\n\n\n\nI will be primarily using Python for exploratory data analysis. This is due to the simplicity of the language making it easier for viewers to follow along with my data manipulation and the complexity of complementary sources, such as its libraries and frameworks. The libraries I am using include Pandas, Matplotlib, Seaborn, Numpy, scikit- learn, and BernoulliNB. While I am using Pandas to sort and manipulate my data, I will be using Matplotlib and Seaborn to visualize any relations I would like to highlight a few of the many possibly influential streaming platform factors on American colloquialism. I will be using Numpy to produce statistical information of my datasets that support my stance and visualizations. In addition to utilizing scikit- learn for producing general algorithms, I will implement BernoulliNB to generate my Naive Bayes algortihm."
  },
  {
    "objectID": "dataexploration.html#data-understanding",
    "href": "dataexploration.html#data-understanding",
    "title": "Data Exploration",
    "section": "",
    "text": "Begin by thoroughly understanding the dataset and the problem you are trying to solve. Familiarize yourself with the characteristics of each feature, including their data types (numerical, categorical), potential relationships, and relevance to the project’s objectives.\nMy collected data is meant to display major representative sources of American pop culture. This currently includes headlines from newpapers, top music songs internationally, and the most liked Netflix shows from the past year. As these sources are known to reflect what the general population is interested in, these datasets that seemingly represent America’s favored pasttimes, also present current wave of cultural influence in America. Of these influences, I aim to see how certain streaming services are most influential on the colloquialisms of America."
  },
  {
    "objectID": "dataexploration.html#descriptive-statistics",
    "href": "dataexploration.html#descriptive-statistics",
    "title": "Data Exploration",
    "section": "",
    "text": "Calculate and report basic summary statistics such as mean, median, mode, standard deviation, and variance for numerical variables. For categorical variables, provide frequency distributions and bar charts to visualize data distribution.\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(appledf.describe())\n\nnewAppledf = appledf.drop([\"Artist and Title\", \"Country\"], axis=1)\nnewAppledf = newAppledf.reset_index(drop=True)\n\nprint(newAppledf.describe())\n\n\n\n\n\nApple Analysis Summary Statistics\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(netflixdf.describe())\n\n\n\n\n\nNetflix Summary Statistics\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(df_new.describe())\nprint(df_newer.describe())\nprint(df_newest.describe())"
  },
  {
    "objectID": "dataexploration.html#data-visualizations",
    "href": "dataexploration.html#data-visualizations",
    "title": "Data Exploration",
    "section": "",
    "text": "Create visualizations such as histograms, box plots, scatter plots, and heatmaps to explore the data’s distribution, relationships between variables, and potential patterns or trends. Visualizations can make complex data more interpretable."
  },
  {
    "objectID": "dataexploration.html#correlation-analysis",
    "href": "dataexploration.html#correlation-analysis",
    "title": "Data Exploration",
    "section": "",
    "text": "Examine the correlations between variables using correlation matrices, heat-maps, or scatter plots. Identify which variables are positively, negatively, or not correlated, which can guide further analysis.\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(appledf.corr())\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(netflixdf.corr())\n\n\n\n\n\n\n\nCode\nimport requests\nimport json\nimport re\nimport pandas as pd\nimport numpy as np\n\nprint(df_new.corr())\nprint(df_newer.corr())\nprint(df_newest.corr())"
  },
  {
    "objectID": "dataexploration.html#hypothesis-generation",
    "href": "dataexploration.html#hypothesis-generation",
    "title": "Data Exploration",
    "section": "",
    "text": "Examples of American pop culture colloquialisms? OR Example of adopted pop culture colloquialisms?\nWhat regions in the United States have more of an effect on shared national colloquialisms?\nWhat regions globally have more of an effect on shared national colloquialisms (limited to seven continents)?\nIs there a specific genre that is more influential on imported jargon?\nIs there a specific region who is more impressionable to imported jargon?\nBased on the data collected, would media or music streaming services be more influential on imported jargon?\nIs national language relation to english influential on how adaptable the terms are?\nDoes positive or negative content have more of an effect on adapted jargon?\nPractical applications for encouraging international colloquialisms dispersal?\nHow can these applications adapt to the growth of international colloquialisms in America?\n\nHypothesis: I believe the rise of international content being consumed through streaming platforms and the rise in the incorporation of internationally- influenced colloquialisms in America will yield a positive correlation."
  },
  {
    "objectID": "dataexploration.html#data-grouping-and-segmentation",
    "href": "dataexploration.html#data-grouping-and-segmentation",
    "title": "Data Exploration",
    "section": "",
    "text": "If applicable, group or segment the data based on relevant criteria to uncover insights within specific subgroups."
  },
  {
    "objectID": "dataexploration.html#identifying-outliers",
    "href": "dataexploration.html#identifying-outliers",
    "title": "Data Exploration",
    "section": "",
    "text": "Detect and investigate outliers that may indicate data quality issues or reveal interesting anomalies in the dataset."
  },
  {
    "objectID": "dataexploration.html#methods-and-findings",
    "href": "dataexploration.html#methods-and-findings",
    "title": "Data Exploration",
    "section": "",
    "text": "Summarize the key findings, insights, and patterns discovered during the EDA phase. Present these findings in a clear and organized manner, using textual narration, tables, charts, and narrative descriptions."
  },
  {
    "objectID": "dataexploration.html#tools-and-software",
    "href": "dataexploration.html#tools-and-software",
    "title": "Data Exploration",
    "section": "",
    "text": "I will be primarily using Python for exploratory data analysis. This is due to the simplicity of the language making it easier for viewers to follow along with my data manipulation and the complexity of complementary sources, such as its libraries and frameworks. The libraries I am using include Pandas, Matplotlib, Seaborn, Numpy, scikit- learn, and BernoulliNB. While I am using Pandas to sort and manipulate my data, I will be using Matplotlib and Seaborn to visualize any relations I would like to highlight a few of the many possibly influential streaming platform factors on American colloquialism. I will be using Numpy to produce statistical information of my datasets that support my stance and visualizations. In addition to utilizing scikit- learn for producing general algorithms, I will implement BernoulliNB to generate my Naive Bayes algortihm."
  },
  {
    "objectID": "DataCleaning.html",
    "href": "DataCleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "All of my detailed data cleaning practices are linked with steps in R and Python. These documents can be found inside the “websitebackupcode” folder on my linked Github repository for my project. This link can be found under the “Data” tab of the website.\n\nData Preparation for Analysis\nIn order to prepare my data for analysis, I attempted to do a general tidying and cleaning of all datasets I would need for the different analyses. To start, this mostly entails reading in any CSV (Comma- Separated Values) files or web scraping an API (Application Programming Interface). Fortunately, the APIs I requested are usually pre- formatted and do not require much cleaning, as much as they would need to be formatted to fit the perspective I want to capture. On the other hand, most of the downloaded CSV datasets happen to have many missing values and are in need of a few extra steps of cleaning.\nOnce I have the raw data I want, Throughout this process, I am checking for missing values in the data and their locations in the datasets, to know if I will need to remove any informative rows or just marginal variables I will not be using.\n\n\nApple Music\nFor my Apple music dataset, I first dropped all missing values. I then melted down variables such as “Pts”, “Days”, and “Peak” to go along with the origin countries of the songs. I then removed anything that was not an integer from the (x?) column to represent the amount of times a song has been at that position. I then saved the cleaned version of my Apple dataset to a new CSV file.\n\n\nSpotify API\nMy Spotify dataset was already put together and void of issues, such as missing values, due to my previous R language request. Thus, the work required to clean the dataset did not require a large amount of time. My column names were generated by the API call, so I renamed all the variables to not include any excess characters. I did not delete any columns, just so my future feature selection is as accurate as possible. I then saved the cleaned dataset to another CSV file.\n\n\n\nCleaning Spotify Dataset in R\n\n\n\n\nNetflix\nFor my Netflix dataset, I renamed my column titles to a more precise description of what my features are meant to capture: the titles of the most- watched television shows and the amount of points each show has. I then deleted the first two rows, as they were repetitive displays of the column names. Last, I checked for any missing elements. Once I could see each column did not contain any missing values, I saved the cleaned dataset to a CSV file that can be found on my Github repository.\n\n\n\nCleaning Netflix Dataset in R\n\n\n\n\nGDP vs Happiness\nMy dataset for the GDP vs. Self- Reported Happiness was quite extensive. As the dataset contained data for countries over many years, I first read in my dataset and then subsetted the dataframe to only show information that pertains to the happiness scores reported for the year 2022. My data source was not able to gather data on the gross domestic product (GDP) per capita for the year 2022 for each country, so I had to delete the column. The column was previously filled with GDP per capita information from the year 2017, so I resorted to gathering my own information on each country’s GDP per capita from the World Bank. As a side note, three countries’ GDP per capita indices were not provided on the World Bank’s site. So, I accessed data from Trading Economics to get the data points for Palestine and South Korea. Likewise, to get the GDP per capita information for Taiwan, I accessed the data information provided by Focus Economics.\nIn addition to dropping the previous “GDP per capita” column, I also eliminated the population, continent, and year (it was all for 2022) data. To precisely capture my dataset’s objective, I then renamed the Cantril Ladder Score column and gave a name to my updated GDP per capita column. Finally, I made sure there were no missing values and then saved the cleaned dataset to a new CSV file.\n\n\n\nCleaning Happiness Dataset in Python\n\n\n\n\nWikipedia API\nMy one other dataset source generated from an API call were my Wikipedia API datasets. For each of the top 5 Netflix shows I wanted to look at, I requested the information from Wikipedia’s website. For each show, I requested the most recent and available season to get access to the premise of the season. Once I was able to receive the premise, I generated a function to remove excess stopwords from the premise. After that, I recorded the sentiment analysis for each word that was left of the premise. Using the Sentiment Intensity Analyzer from the Natural Language Toolkit’s sentiment package, I could now see which words were considered negative, neutral, and positive and their associated sentiment compound scores. These variables were put in a dataframe once completed. I noticed that some dataframes considered “’s” as a word, so I had them removed as a final step before saving the dataset to a CSV file.\nOnce each television show premise was made into its own dataframe and saved to its own CSV file, I combined them. I did a vertical concatenation on the top five Netflix television shows as a final step before analysis commenced.\n\n\n\nCleaning Wikipedia Dataset in Python\n\n\nFor reference, I have posted my data cleaning process for one of my datasets– the Apple Music dataset. In the “Data Gathering” tab, you can see a general idea of what the original, raw dataset looks like. Additionally, the Apple Music dataset and all my other datasets are in the “websitedata” folder on my linked Github repository. Now, shown below, you can see a visual of my R cleaning inputs to form my dataset the way I need it for analysis. Right below that image, you can also see a visual of my cleaned dataset of top international rankings for Apple Music in 2023.\n\n\n\nCleaning Apple Dataset in R\n\n\n\n\n\nCleaned Apple Dataset\n\n\nSimilarly, as a second reference, right below this is a visual of my text sentiment analysis for Stranger Things, Season 3. The vectors display whether the analyzed word falls under the category of “neg” for negative, “neu” for neutral, and “pos” for positive. The last column labeled “compound” is the calculated net sentiment score. Right below that visual, is another image of vertical concatenation operation to combine all television shows."
  }
]